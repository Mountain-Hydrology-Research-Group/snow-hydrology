{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files required for this lab are large, so they are not downloadable directly from the website. \n",
    "\n",
    "Download them from the following link: \n",
    "\n",
    "https://drive.google.com/drive/folders/1I8DEuj2ddT1TKXhBvVBL1lHJvbd2D_S0?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redistribution of the snowpack by blowing snow - infilling of depressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we open a lidar dataset. The lidar was mounted at 10 meters above the ground, pointing at an angle towards the ground. The dataset contains values of \"distance from the lidar\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('../data/dec22_l1_clip.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(time=slice('20221222', '20221222'))['surface'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at a histogram of values, we can see that the distribution of values ranges from -14 to -8, which makes sense for the lidar mounted at 10m, pointed at an angle towards the ground."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While values of \"distance from the ground\" are hard to interpret, if we subtract two snapshots from eachother, we will calculate the change in snow-surface elevation.\n",
    "\n",
    "Below, we do just this, calculating the difference in snow surface elevation between Dec 21 12am and Dec 23 12am, which according to Lundquist et al., 2024 (from earlier in the class), is the timing of a major blowing snow event that filled in a depression at the field site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "ds.sel(time='20221221 0000')['surface'].plot(vmin=-14, vmax=-10, ax=axes[0])\n",
    "ds.sel(time='20221223 0000')['surface'].plot(vmin=-14, vmax=-10, ax=axes[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds.sel(time='20221223 0000')['surface'] - ds.sel(time='20221221 0000')['surface']).plot(vmin=-1, vmax=1, cmap='bwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the depression infilling over 48 hours above. This is also shown in Lundquist et al. (2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blowing snow - snow dunes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we open some lidar data from March 23, a day on which we observed the formation and migration of snow dunes across the Kettle Ponds site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('../data/mar23_l1_clip.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at a single snapshot, we see that the snow surface at Kettle Ponds in March was sloping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_snapshot = ds.sel(time = ds.time[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_snapshot['surface'].plot(vmin=-10, vmax=-9, cmap='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to see what's going on with the snow surface here. \n",
    "\n",
    "What we want to look at is deviations around that mean sloping surface.\n",
    "\n",
    "We can calculate this. First, we calculate the mean across time for each pixel. Then we subtract that pixel-wise mean from a timestamp, which will reveal the snow surface topgraphy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pixel-wise mean from the entire dataset\n",
    "pixel_wise_mean = np.nanmean(ds['surface'], axis=(0))\n",
    "\n",
    "# Select a specific time stamp from the dataset\n",
    "specific_timestamp = ds['surface'].sel(time = ds.time[19])\n",
    "\n",
    "# Subtract the pixel-wise mean from the specific timestamp\n",
    "# We call this the \"normalized\" dataset\n",
    "normed = specific_timestamp - pixel_wise_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed.plot(vmin=-0.5, vmax=0.7, cmap='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! We can see snow dunes!\n",
    "\n",
    "How can we tell if these dunes are migrating? Let's plot multiple snapshots, sequential in time, next to eachother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_timestamp_1 = ds['surface'].sel(time = ds.time[19])\n",
    "normed_1 = specific_timestamp_1 - pixel_wise_mean\n",
    "\n",
    "specific_timestamp_2 = ds['surface'].sel(time = ds.time[20])\n",
    "normed_2 = specific_timestamp_2 - pixel_wise_mean\n",
    "\n",
    "specific_timestamp_3 = ds['surface'].sel(time = ds.time[21])\n",
    "normed_3 = specific_timestamp_3 - pixel_wise_mean\n",
    "\n",
    "specific_timestamp_4 = ds['surface'].sel(time = ds.time[22])\n",
    "normed_4 = specific_timestamp_4 - pixel_wise_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(10,10))\n",
    "normed_1.plot(vmin=-0.5, vmax=0.7, cmap='seismic', ax=axes.flatten()[0])\n",
    "normed_2.plot(vmin=-0.5, vmax=0.7, cmap='seismic', ax=axes.flatten()[1])\n",
    "normed_3.plot(vmin=-0.5, vmax=0.7, cmap='seismic', ax=axes.flatten()[2])\n",
    "normed_4.plot(vmin=-0.5, vmax=0.7, cmap='seismic', ax=axes.flatten()[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's still kind of hard to tell... let's create a GIF from all timestamps in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT wrote the function below\n",
    "\n",
    "# Define a function named create_gif_from_plots that takes two arguments: ds (lidar dataset) and output_gif (name of the output GIF file)\n",
    "def create_gif_from_plots(ds, output_gif):\n",
    "    # Create an empty list to store the filenames of the plot images\n",
    "    filenames = []\n",
    "    \n",
    "    # Iterate over all time steps in the lidar dataset\n",
    "    for i, time_step in enumerate(ds.time):\n",
    "        # Normalize the data by subtracting the pixel-wise mean from the surface values at the current time step\n",
    "        normed = ds.sel(time=time_step)['surface'] - np.nanmean(ds['surface'], axis=(0))\n",
    "        # Create a new plot figure\n",
    "        plt.figure()\n",
    "        # Plot the normalized data using a colormap and set the color range\n",
    "        normed.plot(vmin=-0.5, vmax=0.7, cmap='seismic')\n",
    "        # Set the title of the plot to indicate the current time step\n",
    "        plt.title(f'Time step: {i}')\n",
    "        # Save the plot as an image file with a filename that includes the current time step index\n",
    "        filename = f'plot_{i}.png'\n",
    "        plt.savefig(filename)\n",
    "        # Append the filename to the list of filenames\n",
    "        filenames.append(filename)\n",
    "        # Close the plot figure to free up memory\n",
    "        plt.close()\n",
    "    \n",
    "    # Create a GIF from the saved image files\n",
    "    with imageio.get_writer(output_gif, mode='I', duration=0.5) as writer:\n",
    "        # Iterate over the filenames of the plot images\n",
    "        for filename in filenames:\n",
    "            # Read the image file\n",
    "            image = imageio.imread(filename)\n",
    "            # Append the image to the GIF writer\n",
    "            writer.append_data(image)\n",
    "    # Optionally, remove the image files after creating the GIF\n",
    "    for filename in filenames:\n",
    "        os.remove(filename)\n",
    "\n",
    "# Example usage\n",
    "# Call the create_gif_from_plots function with the lidar dataset 'ds' as the argument\n",
    "create_gif_from_plots(ds, 'lidar_timeseries.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url='output.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the gif - do you see the dune migration? Cool!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-hydrology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
